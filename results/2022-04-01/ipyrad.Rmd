---
title: "ipyrad analysis 0.85"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Assembly analysis

The goal of the assembly process is to convert raw or sorted `fastq`data into assembled loci that can be formatted for downstream analyses in phylogenetic or population genetic inference software. `ipyrad`offers an atomized process of seven sequential steps to create a modular workflow that can be easily restarted if interrupted, and can be branched at different points to create assemblies under different combinations of parameter settings.

## Step 0 - Loading `fastq`files

In our case, we have a library with multiple lanes of sequencing for each sample. To begin with the assembly process, we have to join these multiple lanes of sequence data that belong to the same library.

`ipyrad` ses a text file to hold all the parameters for a given assembly. So first, we create two separate demux assemblies (for Run1 and Run2) that will create two new params files, followed by the assembly name. The params file lists in each line one parameter, followed by a \#\# mark, the name of the parameter, and then a short description of its prupose. Some of the parameters have default values (which we are not going to change in this step), but there are a few parameters that we must change before beginning demultiplexing (since they affect this step):

-   `[0] [assembly_name]`. Used to name output directories for assembly steps.
-   `[1] [project_dir]`: Project directory (made in curdir if not present)
-   `[2] [raw_fastq_path]`: Location of raw non-demultiplexed fastq files (empty line)
-   `[3] [barcodes_path]`: Location of barcodes file (empty line)
-   `[4] [sorted_fastq_path]`: Location of demultiplexed/sorted fastq files
-   `[5] [assembly_method]`: Assembly method (`reference`)
-   `[6] [reference_sequence]`: Location of reference sequence file
-   `[7] [datatype]`: Datatype (`pairddrad`)
-   `[8] [restriction_overhang]`: Restriction overhang (empty line)
-   `[15] [max_barcode_mismatch]`: Max number of allowable mismatches in barcodes (`0`)

```{bash}

conda activate ipyrad

## create demux Assembly object for Runs 1 and 2
ipyrad -n run1
ipyrad -n run2

## edit the params to enter its raw_fastq_path and barcodes file
#nano params-run1.txt
#nano params-run2.txt

## visualize the changes in .txt
cat params-run1.txt
cat params-run2.txt
```

## Step 1 - Demultiplexing

Next, we run Step 1 for both assemblies and merge them. Because the two demultiplexed lanes each use the same barcodes file, the Samples will have identical names. `ipyrad` will recognize this during merging and read both input files for each Sample in Step 2.

```{bash}
# demultiplex Run1 and Run2
ipyrad -p params-run1.txt -s 1
ipyrad -p params-run2.txt -s 1

#show results 
#ipyrad -p params-run1.txt -r
#ipyrad -p params-run2.txt -r

# merge the two runs 
ipyrad -m both params-run1.txt params-run2.txt

```

## Steps 2 and 3 - Filtering and Clustering within-samples

**Step 2** filters reads based on quality scores and **Step 3** de-replicates and clusters reads within each sample by the set clustering threshold. Step 3 is one of the most intensive steps and it is expected to take quite a bit longer than the other steps.

The parameters changed (in `params_both.txt`) in these Steps are:

-   `[9] [max_low_qual_bases]`: Max low quality base calls (Q\<20) in a read (set to `4`)
-   `[10] [phred_Qscore_offset]`: phred Q score offset (set to `33`)
-   `[14] [clust_threshold]`: Clustering threshold for de novo assembly (set to `0.85`)
-   `[16] [filter_adapters]`: Filter for adapters/primers (set to `2`)
-   `[17] [filter_min_trim_len]`: Min length of reads after adapter trim (set to `35`)
-   `[25] [trim_reads]`: Trim raw read edges (`0, -10, 0, -10`)

```{bash}
ipyrad -p params-both.txt -s 23 -c 24
ipyrad -p params-both.txt -r
```

In Step 3, clustering was done according to 85% similarity between the mapping sequences. We want to try with some different parameters and analyze the sequences to see which of the results fits our wishes. For this reason we create a branching of the results obtained in Step 3, called `assem2.` From here, two assemblies with different configurations in the parameters will be analyzed. At the moment we continue with the Assembly clustered according to 85% similarity.

### Branching to create a new assembly

```{bash}

## Create a new branch of the Assembly "both"
ipyrad -p params_both.txt -b assem2

## Move the new files into a new folder
# mv assem2.json params_assem2.txt ~/cophyhopa/results/2022-04-22
```

## Steps 4 to 7 - Heterozygosity, consensus base calls, clustering and filtering

**Step 4** jointly estimates sequencing error rate and heterozygosity to disentangle which reads are "real" and which are sequencing error. This is useful due to in diploid organisms there are a maximum of 2 alleles at any given locus. **Step 5** uses the output of Step 4 (error rate and heterozygosity) to call the consensus of sequences within each cluster. So, here we identify what we believe to be the haplotypes at each locus within each sample. **Step 6** clusters consensus sequences across samples obtained above. We use the same clustering threshold as step 3 to identify sequences between samples that are probably sampled from the same locus, based on sequence similarity. Finally, **Step 7** filters the data and write output files in the desired format. This can be: PHYLIP (Full data set, SNPs only or One SNP per locus), NEXUS, STRUCTURE, EIGENSTRAT (.geno), G-PhoCS and VCF (SNPs only).

The parameters changed (in `params_both.txt`) in these Steps are:

-   `[11] [mindepth_statistical]`: Min depth for statistical base calling (set to `6`)
-   `[12] [mindepth_majrule]`: Min depth for majority-rule base calling (set to `6`)
-   `[13] [maxdepth]`: Max cluster depth within samples (set to `10000`)
-   `[14] [clust_threshold]`: Clustering threshold for de novo assembly (set to `0.85`)
-   `[18] [max_alleles_consens]`: Max alleles per site in consensus sequences (set to `2`)
-   `[19] [max_Ns_consens]`: Max N's (uncalled bases) in consensus (set to `0.05`)
-   `[20] [max_Hs_consens]`: Max Hs (heterozygotes) in consensus (set to `0.05`)
-   `[21] [min_samples_locus]`: Min \# samples per locus for output (set to `4`)
-   `[22] [max_SNPs_locus]`: Max \# SNPs per locus (set to `0.1`)
-   `[23] [max_Indels_locus]`: Max \# of indels per locus (set to `2`)
-   `[24] [max_shared_Hs_locus]`: Max \# heterozygous sites per locus (set to `0.5`)
-   `[26] [trim_loci]`: Trim locus edges (`0, 0, 0, 0`)
-   `[27] [output_formats]`: Output formats (set to `*` -all-)
-   `[28] [pop_assign_file]`: Path to population assignment file

```{bash}
ipyrad -p params-both.txt -s 456 -c 48
ipyrad -p params-both.txt -r

ipyrad -p params-both.txt -s 7 -c 24
```

## Final stats output

```{bash}
less ZUR/both_outfiles/both_stats.txt

less ZUR/both_outfiles/both.loci

```
